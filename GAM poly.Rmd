---
title: "R Notebook"
output: html_notebook
---

```{r}


#setup multitheading
library(doParallel)

cores = detectCores()


```


```{r}

library(dplyr)
library(tidymodels)
library(usemodels)
## Assume you save the training data in the folder "C:/temp" in your local laptop
traindata <- read.table(file = "C:/temp/7406train.csv", sep=",");
dim(traindata);
## dim=10000*202
## The first two columns are X1 and X2 values, and the last 200 columns are the Y valus

### Some example plots for exploratory data analysis
### please feel free to add more exploratory analysis
testX  <- read.table(file = "C:/temp/7406test.csv", sep=",")
names(traindata)[names(traindata) == 'V1'] = 'X1'
names(traindata)[names(traindata) == 'V2'] = 'X2'
names(testX)[names(testX) == 'V1'] = 'X1'
names(testX)[names(testX) == 'V2'] = 'X2'
X1 <- traindata[,1];
X2 <- traindata[,2];

## note that muhat = E(Y) and Vhat = Var(Y)
muhat <- apply(traindata[,3:202], 1, mean);
Vhat  <- apply(traindata[,3:202], 1, var)

data0 = data.frame(X1 = X1, X2=X2, muhat = muhat, Vhat = Vhat)


```



```{r}
#tidy models learning stuff

set.seed(123)


#splitting data
split = initial_split(data0)
train = training(split)
test = testing(split)

set.seed(234)
folds = bootstraps(train)

```




```{r}
library(splines)


```


```{r}
# Recipe with polynomial features and interaction
muhat_spline_rec <- recipe(muhat ~ X1 + X2, data = train) %>%
  step_poly(X1, degree = tune("x1_degree")) %>%  # Polynomial for X1
  step_poly(X2, degree = tune("x2_degree")) %>%  # Polynomial for X2
  step_interact(terms = ~ starts_with("X1"):starts_with("X2"))  # Interaction

# Model specification
lm_spec <- linear_reg() %>% 
  set_engine("glm")  # Use glmnet or stan if needed

# Workflow
muhat_spline_wf <- workflow() %>%
  add_recipe(muhat_spline_rec) %>%
  add_model(lm_spec)

# Tuning grid
spline_grid <- expand.grid(
  x1_degree = c(1:10), 
  x2_degree = c(1:10)
)

# Register parallel backend
doParallel::registerDoParallel()

# Control for saving predictions
save_preds <- control_grid(save_pred = TRUE)

# Tuning
spline_mu <- tune_grid(
  muhat_spline_wf,
  resamples = folds,
  grid = spline_grid,
  control = save_preds
)

# Stop parallel processing
doParallel::stopImplicitCluster()

# Evaluate Results
collect_metrics(spline_mu)



```


```{r}
Best_muhat = select_best(spline_mu, metric = 'rmse')
Best_muhat
```


```{r}
Final_mu = finalize_workflow(muhat_spline_wf, Best_muhat )
Final_mu
```


```{r}
mu_spline_test = last_fit(Final_mu, split)
collect_metrics(mu_spline_test)
```


```{r}

Final_Mu_model <- extract_workflow(mu_spline_test)

predicted_mean = predict(Final_Mu_model, new_data = testX)


predicted_mean

```

```{r}

testX


```


```{r}

testX$muhat = predicted_mean$.pred
testX
```



```{r}
#tidy models learning stuff

set.seed(123)


#splitting data
split = initial_split(data0)
train = training(split)
test = testing(split)

set.seed(234)
folds = bootstraps(train)

```




```{r}
library(splines)


```


```{r}
# Recipe with polynomial features and interaction
Vhat_spline_rec <- recipe(Vhat ~ X1 + X2, data = train) %>%
  step_poly(X1, degree = tune("x1_degree")) %>%  # Polynomial for X1
  step_poly(X2, degree = tune("x2_degree")) %>%  # Polynomial for X2
  step_interact(terms = ~ starts_with("X1"):starts_with("X2"))  # Interaction

# Model specification
lm_spec <- linear_reg() %>% 
  set_engine("lm")  # Use glmnet or stan if needed

# Workflow
Vhat_spline_wf <- workflow() %>%
  add_recipe(Vhat_spline_rec) %>%
  add_model(lm_spec)

# Tuning grid
spline_grid <- expand.grid(
  x1_degree = c(1:15), 
  x2_degree = c(1:15)
)

# Register parallel backend
doParallel::registerDoParallel()

# Control for saving predictions
save_preds <- control_grid(save_pred = TRUE)

# Tuning
spline_vhat <- tune_grid(
  Vhat_spline_wf,
  resamples = folds,
  grid = spline_grid,
  control = save_preds
)

# Stop parallel processing
doParallel::stopImplicitCluster()

# Evaluate Results
collect_metrics(spline_vhat)
show_best(spline_vhat, metric = "rmse")
```

```{r}
Best_Vhat = select_best(spline_vhat, metric = 'rmse')
Best_Vhat
```


```{r}
Final_V = finalize_workflow(Vhat_spline_wf, Best_Vhat )
Final_V
```


```{r}
V_spline_test = last_fit(Final_V, split)
collect_metrics(V_spline_test)
```

```{r}

Final_V <- extract_workflow(V_spline_test)

predicted_variance = predict(Final_V, new_data = testX)


predicted_variance


```


```{r}
testX$vhat = predicted_variance$.pred


```


```{r}
testX
```


```{r}
write.csv(testX, "predictions.csv", row.names = FALSE)

```


```{r}
getwd()
```


```{r}
library(rgl)

# 3D scatter plot for muhat
plot3d(testX$X1, testX$X2, testX$muhat,
       type = 'p',
       col.grid = 'grey',
       col = gray(seq(0, .45, length.out = length(testX$muhat))),  # Grayscale palette,
       size = 3,
       xlab = "X1", ylab = "X2", zlab = "(muhat)",
       main = "")



```


```{r}
# 3D scatter plot for Vhat
plot3d(testX$X1, testX$X2, testX$vhat,
       col = gray(seq(0, .45, length.out = length(testX$muhat))),
       size = 3,
       xlab = "X1", ylab = "X2", zlab = "(Vhat)",
       main = "")
```




```{r}
Final_V$fit
```
